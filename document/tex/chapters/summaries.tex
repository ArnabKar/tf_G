% !TEX root = ../../document.tex

\documentclass{subfiles}

\begin{document}

  \chapter{Estructuras de Datos de Resumen}
  \label{chapter:summaries}

    \section{Introducción}
    \label{sec:summaries_intro}

      \paragraph{}
      El gran crecimiento tecnológico que se está llevando a cabo en la actualidad a todos los niveles está propiciando además un aumento exponencial en cuanto a la cantidad de información que se genera. La reducción de costes en cuanto a la instalación de sensores que permiten recoger información de muchos procesos productivos, así como la obtenición de metadatos a partir del uso de internet y las redes sociales por parte de los usuarios hace que el ritmo de crecimiento en cuanto a información generada por unidad de tiempo haya crecido a un gran ritmo.

      \paragraph{}
      Una de las razones que han facilitado dicha tendencia es la disminución de costes de almacenamiento de información a la vez que las capacidades de cómputo necesarias para procesar dicha información han aumentado. Sin embargo, debido al crecimiento exponencial en cuanto al tamaño del conjunto de datos, es necesario investigar nuevas técnicas y estrategias que permitan obtener respuestas satisfactorias basadas en la gran cantidad de información de la que se dispone en un tiempo razonable.

      \paragraph{}
      Tradicionalmente, la investigación en el campo de las \emph{bases de datos} se ha centrado en obtener respuestas exactas a distintas consultas, tratando de hacerlo de la manera más eficiente posible, así como de tratar de reducir el espacio necesario para almacenar la información. \emph{Acharya y otros} proponen en el artículo \emph{Join synopses for approximate query answering} \cite{acharya1999join} el concepto de \emph{Approximate Query Processing}. Dicha idea se expone en la subsección \ref{sec:aproximate_query_processing}.

      \subsection{Approximate Query Processing}
      \label{sec:aproximate_query_processing}

        \paragraph{}
        El \emph{procesamiento aproximado de consultas}, (\emph{Approximate Query Processing} o \textbf{AQP}) se presenta como una estrategia de consulta basada en conceptos y propiedades estadísticas que permiten una gran reducción de la complejidad computacional y espacial necesaria para la resolución de consultas a una base de datos. Por contra, dicha reducción a nivel de complejidad tiene como consecuencia la inserción de un determinado nivel de imprecisión en el resultado a la cual denominaremos tasa de error. Se pretende que dicha tasa de error pueda ser acotada en una desviación máxima determinada por $\epsilon$ y se cumpla con un índice de probabilidad $\delta$. Al igual que en capítulos anteriores, en este caso también se presta especial importancia en la minimización del error relativo lo cual consigue que las soluciones mediante el \emph{procesamiento aproximado de consultas} sean válidas tanto para consultas de tamaño reducido como de gran tamaño.


      \paragraph{}
      Durante el resto del capítulo se describen y analizan distintas estrategias que permiten llevar a cabo implementaciones basadas en \emph{procesamiento aproximado de consultas} centrando especial atención en los \emph{Sketches} por su similitud con el \emph{Modelo en Streaming} descrito en el capítulo \ref{chapter:streaming}. En la sección \ref{sec:summaries_types} se realiza una decripción a partir de la cual se pretende aclarar las diferencias entre las distintas \emph{estructuras de datos de resumen}. Posteriormente, en la sección \ref{sec:sketching} se explican en detalle las cualidades de las estrategias basadas en \emph{Sketching}. En las secciones \ref{sec:count_min_sketch}, \ref{sec:count_sketch}, \ref{sec:ams_sketch} y \ref{sec:hyper_log_log} se habla de \emph{Count-Min Sketch}, \emph{Count Sketch}, \emph{AMS Sketch} e \emph{HyperLogLog} respectivamente.


    \section{Tipos de Estructuras de Datos de Resumen}
    \label{sec:summaries_types}

      \paragraph{}
      Para el diseño de soluciones basadas en \emph{procesamiento aproximado de consultas} en bases de datos existen distintas estrategias, las cuales presentan distintas ventajas e inconvenientes tal y como se pretende mostrar en esta sección. Dichas descripciones han sido extraidas del libro \emph{Synopses for massive data} \cite{cormode2012synopses} redactado por \emph{Cormode y otros}. En las secciones \ref{sec:sampling}, \ref{sec:histogram}, \ref{sec:wavelet} y \ref{sec:sketch} se habla de \emph{Sampling}, \emph{Histogram}, \emph{Wavelet} y \emph{Sketches} respectivamente.

      \subsection{Sampling}
      \label{sec:sampling}

        \paragraph{}
        El \emph{Sampling} o \emph{muestreo} es la estrategia más consolidada entre las que se presentan. Las razones se deben a su simplicidad conceptual así como su extendido uso en el mundo de la estadística. La intuición en que se basa dicha estrategia es la selección de un subconjunto de elementos denominado \emph{muestra} de entre el conjunto global al cual se denomina \emph{población}. Una vez obtenida la \emph{muestra} del conjunto de datos global cuyo tamaño es significativamente menor (lo cual reduce drásticamente el coste computacional), se realizan los cálculos que se pretendía realizar sobre toda la \emph{población}, a partir de los cuales se obtiene un estimador del valor real que habría sido obtenido al realizarlos sobre el conjunto de datos global.

        \paragraph{}
        Para que las estrategias de sumarización de información obtengan resultados válidos o significativos respecto del conjunto de datos, es necesario que se escojan adecuadamente las instancias de la \emph{muestra}, de manera que represente de manera fiel la información global. Para llevar a cabo dicha labor existen distintas estrategias, desde las más simples basadas en la selección aleatoria sin reemplazamiento como otras mucho más sofisticadas basadas en el mantenimiento de \emph{muestras} estratificadas. Sea $R$ la población y $|R|$ el tamaño de la misma. Denominaremos $t_j$ al valor $j$-ésimo de la población y $X_j$ al número de ocurrencias del mismo en la \emph{muestra}. A continuación se describen distintas técnicas de muestreo:

        \begin{itemize}

          \item \textbf{Selección Aleatoria Sin Reemplazamiento}: Consiste en la estrategia más simple de generación de \emph{muestras}. Se basa en la selección aleatoria de un valor entero $r$ en el rango $[1, |R|]$ para después añadir el elemento localizado en la posición $r$ de la \emph{población} al subconjunto de \emph{muestra}. Después repetir dicha secuencia durante $n$ veces para generar una \emph{muestra} de tamaño $n$. El estimador para la operación \emph{SUMA} se muestra en la ecuación \eqref{eq:sum_with_replacement} además de la desviación de dicho estimador en la ecuación \eqref{eq:sum_with_replacement_deviation}.
            \begin{align}
            \label{eq:sum_with_replacement}
              Y &= \frac{|R|}{n}\sum_jX_jt_j \\
            \label{eq:sum_with_replacement_deviation}
              \sigma^2(Y) &= \frac{|R|^2\sigma^2(R)}{n}
            \end{align}

          \item \textbf{Selección Aleatoria Con Reemplazamiento}: En este caso se supone que la selección de una instancia de la población tan solo se puede llevar a cabo una única vez como mucho, por lo tanto se cumple que $\forall X_j \in {0,1}$. La selección se lleva a cabo de la siguiente manera: se genera de manera aleatoria un valor entero $r$ en el rango $[1, |R|]$ para después añadir el elemento localizado en la posición $r$ de la \emph{población} al subconjunto de \emph{muestra} si este no ha sido añadido ya, sino volver a generar otro valor $r$. Después repetir dicha secuencia durante $n$ veces para generar una \emph{muestra} de tamaño $n$. Al igual que en la estrategia anterior, en este caso también se muestra el estimador para la operación \emph{SUMA} en la ecuación \eqref{eq:sum_without_replacement}. Nótese que el cálculo es el mismo que en el caso de la estrategia sin reemplazamiento. Sin embargo, la varianza obtenida a partir de dicha estrategia es menor tal y como se muestra en la ecuación \eqref{eq:sum_without_replacement_deviation}.
            \begin{align}
            \label{eq:sum_without_replacement}
              Y &= \frac{|R|}{n}\sum_jX_jt_j \\
            \label{eq:sum_without_replacement_deviation}
              \sigma^2(Y) &= \frac{|R|(|R| - n)\sigma^2(R)}{n}
            \end{align}

          \item \textbf{Bernoulli y Poisson}: Mediante esta alternativa de muestreo se sigue una estrategia completamente distinta a las anteriores. En lugar de seleccionar la siguiente instancia aleatoriamente de entre todas las posibles, se decide generar $|R|$ valores aleatorios $r_j$ independientes en el intervalo $[0,1]$ de tal manera que si $r_j$ es menor que un valor $p_j$ fijado a priori, la instancia se añade al conjunto de \emph{muestra}. Cuando se cumple que $\forall i, j \ p_i = p_j$ se dice que es un muestreo de \emph{Bernoulli}, mientras que cuando no se cumple dicha condición se habla de muestreo de \emph{Poisson}. El cálculo de la \emph{SUMA} en este caso es muy diferente de los anteriores tal y como se muestra en la ecuación \eqref{eq:sum_bernoulli_poisson}. La desviación de este estimador se muestra en la ecuación \eqref{eq:sum_bernoulli_poisson_deviation}, que en general presenta peores resultados (mayor desviación) que las anteriores alternativas, sin embargo, esta alternativa posee la cualidad de aplicar distintos pesos a cada instancia de la población, lo que puede traducirse en que una selección adecuada de dichos valores $p_j$ puede mejorar significativamente dichos resultados.
            \begin{align}
            \label{eq:sum_bernoulli_poisson}
              Y &= \sum_{i \in muestra }\frac{t_i}{p_i} \\
            \label{eq:sum_bernoulli_poisson_deviation}
              \sigma^2(Y) &= \sum_i(\frac{1}{p_i}-1)t_i^2
            \end{align}

          \item \textbf{Muestreo Estratificado}: El muestreo estratificado trata de minimizar al máximo las diferencias entre la distribución del conjunto de datos de la \emph{población} de la \emph{muestra} que se pretende generar. Para ello existen distintas alternativas entre las que se encuentra una selección que  actualiza los pesos $p_j$ tras cada iteracción, lo que reduce la desviación de la \emph{muestra}, sin embargo produce un elevado coste computacional en su generación. Por lo tanto se proponen otras estrategia más intuitiva basada en la partición del conjunto de datos de la \emph{población} en subconjuntos disjuntos con varianza mínima entre las instancias que contienen a los cuales se denomina \emph{estratos}. Posteriormente se selecciona mediante cualquiera de los métodos anteriores una \emph{muestra} de cada \emph{estrato}, lo cual reduce en gran medida la desviación típica global del estimador.

        \end{itemize}

        \paragraph{}
        [TODO ]


        \paragraph{}
        La estrategia del \emph{muestreo} es válida para consultas relacionadas con propieda



      \subsection{Histogram}
      \label{sec:histogram}

        \paragraph{}
        [TODO ]

      \subsection{Wavelet}
      \label{sec:wavelet}

        \paragraph{}
        [TODO ]

      \subsection{Sketch}
      \label{sec:sketch}

        \paragraph{}
        [TODO ]

    \section{Sketching}
    \label{sec:sketching}

      \paragraph{}
      [TODO ]

    \section{Count-Min Sketch}
    \label{sec:count_min_sketch}

      \paragraph{}
      [TODO ]

    \section{Count Sketch}
    \label{sec:count_sketch}

      \paragraph{}
      [TODO ]

    \section{AMS Sketch}
    \label{sec:ams_sketch}

      \paragraph{}
      [TODO ]

    \section{HyperLogLog}
    \label{sec:hyper_log_log}

      \paragraph{}
      [TODO ]


\end{document}
